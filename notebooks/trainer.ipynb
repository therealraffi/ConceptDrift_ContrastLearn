{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8664b1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/rhm4nj/ml-sec/mlsec/lib/python3.11/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /sfs/weka/scratch/rhm4nj/ml-sec/mlsec/lib/python3.11/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/scratch/rhm4nj/ml-sec/mlsec/lib/python3.11/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /sfs/weka/scratch/rhm4nj/ml-sec/mlsec/lib/python3.11/site-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "/scratch/rhm4nj/ml-sec/mlsec/lib/python3.11/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /sfs/weka/scratch/rhm4nj/ml-sec/mlsec/lib/python3.11/site-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(\n",
      "/scratch/rhm4nj/ml-sec/mlsec/lib/python3.11/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /sfs/weka/scratch/rhm4nj/ml-sec/mlsec/lib/python3.11/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import HeteroConv, GCNConv, global_mean_pool\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import HeteroData, Batch\n",
    "\n",
    "from relation_graph import RelationGraph\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from my_models import *\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b51b108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done loading metadata\n",
      "done loading relation graph\n",
      "max possible pairs (approx): 1,037,697,346\n",
      "loading pairs from /scratch/rhm4nj/ml-sec/data/dataset/pairs.pkl\n",
      "Num pairs 50000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"config.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "paths = config[\"paths\"]\n",
    "train_cfg = config[\"training\"]\n",
    "\n",
    "meta = pd.read_csv(paths[\"meta_csv\"], parse_dates=[\"datetime\"]).set_index(\"apk_id\")\n",
    "print(\"done loading metadata\")\n",
    "\n",
    "type_map = {'package':1, 'class':2, 'method':3, 'permission':4}\n",
    "rel_map = {\n",
    "    1:'function_of',2:'class_of',3:'inheritance',\n",
    "    4:'uses_parameter',5:'returns',6:'throws',\n",
    "    7:'alternative',8:'conditional',9:'refers_to',10:'uses_permission'\n",
    "}\n",
    "rg = RelationGraph(paths[\"rel_path\"], paths[\"ent_path\"], type_map, rel_map)\n",
    "print(\"done loading relation graph\")\n",
    "\n",
    "sample_path = next(Path(paths[\"graph_dir\"]).glob(\"*.gpickle\"))\n",
    "with open(sample_path, \"rb\") as f:\n",
    "    nxg = pickle.load(f)\n",
    "metadata = to_heterodata(nxg, rg).metadata()\n",
    "\n",
    "dataset = ContrastiveGraphDataset(\n",
    "    graph_dir=paths[\"graph_dir\"],\n",
    "    meta=meta,\n",
    "    rg=rg,\n",
    "    metadata=metadata,\n",
    "    num_pairs=train_cfg[\"num_pairs\"],\n",
    "    sample_pairs=train_cfg[\"sample_pairs\"],\n",
    "    pair_file=paths[\"pair_file\"],\n",
    "    save_pairs=train_cfg[\"save_pairs\"],\n",
    ")\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=train_cfg[\"batch_size\"], shuffle=True, collate_fn=collate_fn)\n",
    "model = HeteroGNN(metadata=metadata).to('cuda')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=train_cfg[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2b985fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.06573\n",
      "Saving - epoch 0 loss 0.0657338781747967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 9/50 [01:02<04:39,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving - epoch 9 loss 0.005904997742618434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 10/50 [01:10<04:41,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Loss: 0.00343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 20/50 [02:19<03:13,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Loss: 0.00353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 30/50 [03:28<02:15,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Loss: 0.00127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 40/50 [04:39<01:09,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Loss: 0.00197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████▊| 49/50 [05:46<00:07,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 | Loss: 0.00115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [05:54<00:00,  7.10s/it]\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(log_dir=paths[\"log_dir\"])\n",
    "label_map = {'strong': 0, 'weak': 1, 'benign_malware': 2}\n",
    "print_epochs = 10\n",
    "max_epochs = 50\n",
    "min_loss = 1000\n",
    "\n",
    "for ep in tqdm(range(max_epochs), desc=\"Training\"):\n",
    "    model.train()\n",
    "    dataset.sample_epoch_pairs()\n",
    "    total = 0\n",
    "\n",
    "    for b1, b2, lbls, dts in loader:\n",
    "        b1, b2 = b1.to('cuda'), b2.to('cuda')\n",
    "        li = torch.tensor([label_map[l] for l in lbls], device='cuda')\n",
    "        dts = dts.to('cuda')\n",
    "\n",
    "        z1 = model.pool(model(b1.x_dict, b1.edge_index_dict), b1.batch_dict)\n",
    "        z2 = model.pool(model(b2.x_dict, b2.edge_index_dict), b2.batch_dict)\n",
    "\n",
    "        loss = hcl_loss(z1, z2, lbls, dts,\n",
    "                        λ1=config[\"loss\"][\"lambda1\"],\n",
    "                        λ2=config[\"loss\"][\"lambda2\"],\n",
    "                        λ3=config[\"loss\"][\"lambda3\"],\n",
    "                        τ=config[\"loss\"][\"tau\"],\n",
    "                        m0=config[\"loss\"][\"m0\"],\n",
    "                        m2=config[\"loss\"][\"m2\"],\n",
    "                        β=config[\"loss\"][\"beta\"])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total += loss.item()\n",
    "\n",
    "    writer.add_scalar(\"Loss/train\", total, ep)\n",
    "    if ep % print_epochs == 0 or ep == max_epochs - 1:\n",
    "        print(f\"Epoch {ep} | Loss: {total:.5f}\")\n",
    "    \n",
    "    if total < min_loss:\n",
    "        min_loss = loss\n",
    "        torch.save(model.state_dict(), paths['ckpt_path'])\n",
    "        print(\"Saving - epoch\", ep, \"loss\", total)\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlsec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
