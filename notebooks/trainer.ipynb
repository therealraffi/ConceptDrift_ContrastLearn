{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8664b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import HeteroConv, GCNConv, global_mean_pool\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import HeteroData, Batch\n",
    "\n",
    "from relation_graph import RelationGraph\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from my_models import *\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b51b108",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"config.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "paths = config[\"paths\"]\n",
    "train_cfg = config[\"training\"]\n",
    "\n",
    "meta = pd.read_csv(paths[\"meta_csv\"], parse_dates=[\"datetime\"]).set_index(\"apk_id\")\n",
    "print(\"done loading metadata\")\n",
    "\n",
    "type_map = {'package':1, 'class':2, 'method':3, 'permission':4}\n",
    "rel_map = {\n",
    "    1:'function_of',2:'class_of',3:'inheritance',\n",
    "    4:'uses_parameter',5:'returns',6:'throws',\n",
    "    7:'alternative',8:'conditional',9:'refers_to',10:'uses_permission'\n",
    "}\n",
    "rg = RelationGraph(paths[\"rel_path\"], paths[\"ent_path\"], type_map, rel_map)\n",
    "print(\"done loading relation graph\")\n",
    "\n",
    "sample_path = next(Path(paths[\"graph_dir\"]).glob(\"*.gpickle\"))\n",
    "with open(sample_path, \"rb\") as f:\n",
    "    nxg = pickle.load(f)\n",
    "metadata = to_heterodata(nxg, rg).metadata()\n",
    "\n",
    "dataset = ContrastiveGraphDataset(\n",
    "    graph_dir=paths[\"graph_dir\"],\n",
    "    meta=meta,\n",
    "    rg=rg,\n",
    "    metadata=metadata,\n",
    "    num_pairs=train_cfg[\"num_pairs\"],\n",
    "    sample_pairs=train_cfg[\"sample_pairs\"],\n",
    "    pair_file=paths[\"pair_file\"],\n",
    "    save_pairs=train_cfg[\"save_pairs\"],\n",
    ")\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=train_cfg[\"batch_size\"], shuffle=True, collate_fn=collate_fn)\n",
    "model = HeteroGNN(metadata=metadata).to('cuda')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=train_cfg[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b985fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir=paths[\"log_dir\"])\n",
    "label_map = {'strong': 0, 'weak': 1, 'benign_malware': 2}\n",
    "print_epochs = 10\n",
    "max_epochs = 50\n",
    "min_loss = 1000\n",
    "\n",
    "for ep in tqdm(range(max_epochs), desc=\"Training\"):\n",
    "    model.train()\n",
    "    dataset.sample_epoch_pairs()\n",
    "    total = 0\n",
    "\n",
    "    for b1, b2, lbls, dts in loader:\n",
    "        b1, b2 = b1.to('cuda'), b2.to('cuda')\n",
    "        li = torch.tensor([label_map[l] for l in lbls], device='cuda')\n",
    "        dts = dts.to('cuda')\n",
    "\n",
    "        z1 = model.pool(model(b1.x_dict, b1.edge_index_dict), b1.batch_dict)\n",
    "        z2 = model.pool(model(b2.x_dict, b2.edge_index_dict), b2.batch_dict)\n",
    "\n",
    "        loss = hcl_loss(z1, z2, lbls, dts,\n",
    "                        λ1=config[\"loss\"][\"lambda1\"],\n",
    "                        λ2=config[\"loss\"][\"lambda2\"],\n",
    "                        λ3=config[\"loss\"][\"lambda3\"],\n",
    "                        τ=config[\"loss\"][\"tau\"],\n",
    "                        m0=config[\"loss\"][\"m0\"],\n",
    "                        m2=config[\"loss\"][\"m2\"],\n",
    "                        β=config[\"loss\"][\"beta\"])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total += loss.item()\n",
    "\n",
    "    writer.add_scalar(\"Loss/train\", total, ep)\n",
    "    if ep % print_epochs == 0 or ep == max_epochs - 1:\n",
    "        print(f\"Epoch {ep} | Loss: {total:.5f}\")\n",
    "    \n",
    "    if total < min_loss:\n",
    "        min_loss = loss\n",
    "        torch.save(model.state_dict(), paths['ckpt_path'])\n",
    "        print(\"Saving - epoch\", ep, \"loss\", total)\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlsec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
